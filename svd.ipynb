{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9], [10, 11, 12]], dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "U, S, V = torch.svd(W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 1.,  2.,  3.],\n",
       "         [ 4.,  5.,  6.],\n",
       "         [ 7.,  8.,  9.],\n",
       "         [10., 11., 12.]]),\n",
       " tensor([[-0.1409,  0.8247,  0.4541],\n",
       "         [-0.3439,  0.4263, -0.3773],\n",
       "         [-0.5470,  0.0278, -0.6078],\n",
       "         [-0.7501, -0.3706,  0.5310]]),\n",
       " tensor([2.5462e+01, 1.2907e+00, 2.7206e-07]),\n",
       " tensor([[-0.5045, -0.7608,  0.4082],\n",
       "         [-0.5745, -0.0571, -0.8165],\n",
       "         [-0.6445,  0.6465,  0.4082]]))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W, U, S, V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 3])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "V.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.7109,  0.9369],\n",
       "        [-1.7356,  0.4843],\n",
       "        [-2.7603,  0.0316],\n",
       "        [-3.7850, -0.4211]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B = U[:, :r] * torch.sqrt(S[:r])\n",
    "B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.5459, -2.8990, -3.2522],\n",
       "        [-0.8643, -0.0649,  0.7345]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.sqrt(S[:r]).unsqueeze(1) * V.t()[:r, :]\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 1.0000,  2.0000,  3.0000],\n",
       "         [ 4.0000,  5.0000,  6.0000],\n",
       "         [ 7.0000,  8.0000,  9.0000],\n",
       "         [10.0000, 11.0000, 12.0000]]),\n",
       " tensor([[ 1.,  2.,  3.],\n",
       "         [ 4.,  5.,  6.],\n",
       "         [ 7.,  8.,  9.],\n",
       "         [10., 11., 12.]]))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B @ A, W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0000,  2.0000,  3.0000],\n",
       "        [ 4.0000,  5.0000,  6.0000],\n",
       "        [ 7.0000,  8.0000,  9.0000],\n",
       "        [10.0000, 11.0000, 12.0000]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(U * torch.sqrt(S)) @ (torch.sqrt(S).unsqueeze(1) * V.t())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0000,  2.0000,  3.0000],\n",
       "        [ 4.0000,  5.0000,  6.0000],\n",
       "        [ 7.0000,  8.0000,  9.0000],\n",
       "        [10.0000, 11.0000, 12.0000]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = 2\n",
    "W_reconstructed = torch.mm(torch.mm(U[:, :r], torch.diag(S[:r])), V[:, :r].t())\n",
    "W_reconstructed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.linalg.matrix_rank(W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv = torch.nn.Conv2d(3, 5, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 3, 3, 3])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv.weight.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([ 0.0293,  0.0547,  0.1739,  0.1672, -0.1361], requires_grad=True)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (1): ReLU()\n",
      "  (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (4): ReLU()\n",
      "  (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (6): Flatten(start_dim=1, end_dim=-1)\n",
      "  (7): Linear(in_features=6272, out_features=10, bias=True)\n",
      ")\n",
      "Sequential(\n",
      "  (0): LoRaConv2d()\n",
      "  (1): ReLU()\n",
      "  (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (3): LoRaConv2d()\n",
      "  (4): ReLU()\n",
      "  (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (6): Flatten(start_dim=1, end_dim=-1)\n",
      "  (7): Linear(in_features=6272, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# 自定义的loraconv2d层\n",
    "class LoRaConv2d(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0):\n",
    "        super(LoRaConv2d, self).__init__()\n",
    "        # 自定义loraconv2d的实现\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 自定义loraconv2d的前向传播逻辑\n",
    "        pass\n",
    "\n",
    "# 递归替换conv2d层为loraconv2d层\n",
    "def replace_conv2d_with_loraconv2d(module):\n",
    "    for name, child in module.named_children():\n",
    "        if isinstance(child, nn.Conv2d):\n",
    "            # 创建一个新的loraconv2d层，使用与原conv2d层相同的参数\n",
    "            new_layer = LoRaConv2d(child.in_channels, child.out_channels, child.kernel_size, child.stride, child.padding)\n",
    "            # 将新的loraconv2d层替换原conv2d层\n",
    "            setattr(module, name, new_layer)\n",
    "        else:\n",
    "            # 递归替换子模块的conv2d层\n",
    "            replace_conv2d_with_loraconv2d(child)\n",
    "\n",
    "# 创建一个示例的nn.Sequential模型\n",
    "model = nn.Sequential(\n",
    "    nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "    nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(128 * 7 * 7, 10)\n",
    ")\n",
    "\n",
    "# 打印原始模型\n",
    "print(model)\n",
    "\n",
    "# 替换所有conv2d层为loraconv2d层\n",
    "replace_conv2d_with_loraconv2d(model)\n",
    "\n",
    "# 打印替换后的模型\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.conv import conv\n",
    "from models.utils import replace_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 10])\n",
      "conv RANK is: 2\n",
      "conv RANK is: 13\n",
      "conv RANK is: 26\n",
      "conv RANK is: 52\n",
      "torch.Size([2, 10])\n",
      "Conv(\n",
      "  (scaler): Scaler()\n",
      "  (layer0): Sequential(\n",
      "    (conv): LoraConv(\n",
      "      (up_conv): Conv2d(3, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (down_conv): Conv2d(2, 64, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (scale): Scaler()\n",
      "    (norm): BatchNorm2d(64, eps=1e-05, momentum=None, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (maxPool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (layer1): Sequential(\n",
      "    (conv): LoraConv(\n",
      "      (up_conv): Conv2d(64, 13, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (down_conv): Conv2d(13, 128, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (scale): Scaler()\n",
      "    (norm): BatchNorm2d(128, eps=1e-05, momentum=None, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (maxPool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (conv): LoraConv(\n",
      "      (up_conv): Conv2d(128, 26, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (down_conv): Conv2d(26, 256, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (scale): Scaler()\n",
      "    (norm): BatchNorm2d(256, eps=1e-05, momentum=None, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (maxPool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (conv): LoraConv(\n",
      "      (up_conv): Conv2d(256, 52, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (down_conv): Conv2d(52, 512, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (scale): Scaler()\n",
      "    (norm): BatchNorm2d(512, eps=1e-05, momentum=None, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (maxPool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (avgPool): AdaptiveAvgPool2d(output_size=1)\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear): Linear(in_features=512, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(2, 3, 32, 32)\n",
    "model = conv([3],  [64, 128, 256, 512], 10)\n",
    "print(model(x).size())\n",
    "# print(model)\n",
    "replace_model(model, 0.125)\n",
    "print(model(x).size())\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = model.layer2.conv.up_conv.weight\n",
    "y = model.layer2.conv.down_conv.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([26, 128, 3, 3]), torch.Size([256, 26, 1, 1]))"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_s, y_s = x.size(), y.size()\n",
    "x_s, y_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = y.view(y_s[0], -1) @ x.view(x_s[0], -1)\n",
    "z.view(y_s[0], x_s[1], x_s[2], x_s[3]).size()\n",
    "z\n",
    "z_bias = torch.zeros((y_s[0]))\n",
    "z_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer0.conv.up_conv.weight\n",
      "layer0.conv.up_conv.bias\n",
      "layer0.conv.down_conv.weight\n",
      "layer0.conv.down_conv.bias\n",
      "layer0.norm.weight\n",
      "layer0.norm.bias\n",
      "layer0.norm.running_mean\n",
      "layer0.norm.running_var\n",
      "layer0.norm.num_batches_tracked\n",
      "layer1.conv.up_conv.weight\n",
      "layer1.conv.up_conv.bias\n",
      "layer1.conv.down_conv.weight\n",
      "layer1.conv.down_conv.bias\n",
      "layer1.norm.weight\n",
      "layer1.norm.bias\n",
      "layer1.norm.running_mean\n",
      "layer1.norm.running_var\n",
      "layer1.norm.num_batches_tracked\n",
      "layer2.conv.up_conv.weight\n",
      "layer2.conv.up_conv.bias\n",
      "layer2.conv.down_conv.weight\n",
      "layer2.conv.down_conv.bias\n",
      "layer2.norm.weight\n",
      "layer2.norm.bias\n",
      "layer2.norm.running_mean\n",
      "layer2.norm.running_var\n",
      "layer2.norm.num_batches_tracked\n",
      "layer3.conv.up_conv.weight\n",
      "layer3.conv.up_conv.bias\n",
      "layer3.conv.down_conv.weight\n",
      "layer3.conv.down_conv.bias\n",
      "layer3.norm.weight\n",
      "layer3.norm.bias\n",
      "layer3.norm.running_mean\n",
      "layer3.norm.running_var\n",
      "layer3.norm.num_batches_tracked\n",
      "linear.weight\n",
      "linear.bias\n"
     ]
    }
   ],
   "source": [
    "for k, v in params.items():\n",
    "    print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "new_params = OrderedDict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in params.items():\n",
    "    if 'conv' in k:\n",
    "        if 'conv.up_conv.weight' in k:\n",
    "            # print(k.split('.')[0])\n",
    "            x = params[k.split('.')[0] + '.conv.up_conv.weight']\n",
    "            y = params[k.split('.')[0] + '.conv.down_conv.weight']\n",
    "            x_s, y_s = x.size(), y.size()\n",
    "            z = y.view(y_s[0], -1) @ x.view(x_s[0], -1)\n",
    "            z = z.view(y_s[0], x_s[1], x_s[2], x_s[3])\n",
    "            z_bias = torch.zeros((y_s[0]))\n",
    "\n",
    "            new_params[k.split('.')[0] + '.conv.weight'] = z\n",
    "            new_params[k.split('.')[0] + '.conv.bias'] = z_bias\n",
    "        else:\n",
    "            continue\n",
    "    else:\n",
    "        new_params[k] = v\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xx = torch.rand((4, 4))\n",
    "xx.view(2, 2, 4)\n",
    "xx.size(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer0.conv.weight\n",
      "layer0.conv.bias\n",
      "layer0.norm.weight\n",
      "layer0.norm.bias\n",
      "layer0.norm.running_mean\n",
      "layer0.norm.running_var\n",
      "layer0.norm.num_batches_tracked\n",
      "layer1.conv.weight\n",
      "layer1.conv.bias\n",
      "layer1.norm.weight\n",
      "layer1.norm.bias\n",
      "layer1.norm.running_mean\n",
      "layer1.norm.running_var\n",
      "layer1.norm.num_batches_tracked\n",
      "layer2.conv.weight\n",
      "layer2.conv.bias\n",
      "layer2.norm.weight\n",
      "layer2.norm.bias\n",
      "layer2.norm.running_mean\n",
      "layer2.norm.running_var\n",
      "layer2.norm.num_batches_tracked\n",
      "layer3.conv.weight\n",
      "layer3.conv.bias\n",
      "layer3.norm.weight\n",
      "layer3.norm.bias\n",
      "layer3.norm.running_mean\n",
      "layer3.norm.running_var\n",
      "layer3.norm.num_batches_tracked\n",
      "linear.weight\n",
      "linear.bias\n"
     ]
    }
   ],
   "source": [
    "for k, v in new_params.items():\n",
    "    print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_params['layer0.conv.weight'].size()\n",
    "nnew_params = OrderedDict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer0.conv.weight\n",
      "2   torch.Size([64, 2])     torch.Size([2, 27])\n",
      "layer0.conv.bias\n",
      "layer1.conv.weight\n",
      "13   torch.Size([128, 13])     torch.Size([13, 576])\n",
      "layer1.conv.bias\n",
      "layer2.conv.weight\n",
      "26   torch.Size([256, 26])     torch.Size([26, 1152])\n",
      "layer2.conv.bias\n",
      "layer3.conv.weight\n",
      "52   torch.Size([512, 52])     torch.Size([52, 2304])\n",
      "layer3.conv.bias\n"
     ]
    }
   ],
   "source": [
    "rate = 0.125\n",
    "for key, value in new_params.items():\n",
    "    if 'conv' in key:\n",
    "        print(key)\n",
    "        if 'weight' in key:\n",
    "            cout, cin, m, n = value.size()\n",
    "            w_2dim = value.view(cout, -1)\n",
    "            rank = int((cin*cout*m*n*rate) / (cout + cin*m*n))\n",
    "            U, S, V = torch.svd(w_2dim)\n",
    "\n",
    "            B = U[:, :rank] * torch.sqrt(S[:rank])\n",
    "            A = torch.sqrt(S[:rank]).unsqueeze(1) * V[:, :rank].t()\n",
    "\n",
    "            print(f\"{rank}   {B.size()}     {A.size()}\")\n",
    "\n",
    "            up_weight = A.view(A.size(0), -1, m, n)\n",
    "            up_bias = torch.zeros((up_weight.size(0)))\n",
    "\n",
    "            down_weight = B.view(B.size(0), B.size(1), 1, 1)\n",
    "            down_bias = torch.zeros((down_weight.size(0)))\n",
    "\n",
    "\n",
    "            nnew_params[key.replace('weight', 'up_conv.weight')] = up_weight\n",
    "            nnew_params[key.replace('weight', 'up_conv.bias')] = up_bias\n",
    "\n",
    "            nnew_params[key.replace('weight', 'down_conv.weight')] = down_weight\n",
    "            nnew_params[key.replace('weight', 'down_conv.bias')] = down_bias            \n",
    "        else:\n",
    "            continue\n",
    "    else:\n",
    "        nnew_params[key] = value\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer0.conv.up_conv.weight\n",
      "layer0.conv.up_conv.bias\n",
      "layer0.conv.down_conv.weight\n",
      "layer0.conv.down_conv.bias\n",
      "layer0.norm.weight\n",
      "layer0.norm.bias\n",
      "layer0.norm.running_mean\n",
      "layer0.norm.running_var\n",
      "layer0.norm.num_batches_tracked\n",
      "layer1.conv.up_conv.weight\n",
      "layer1.conv.up_conv.bias\n",
      "layer1.conv.down_conv.weight\n",
      "layer1.conv.down_conv.bias\n",
      "layer1.norm.weight\n",
      "layer1.norm.bias\n",
      "layer1.norm.running_mean\n",
      "layer1.norm.running_var\n",
      "layer1.norm.num_batches_tracked\n",
      "layer2.conv.up_conv.weight\n",
      "layer2.conv.up_conv.bias\n",
      "layer2.conv.down_conv.weight\n",
      "layer2.conv.down_conv.bias\n",
      "layer2.norm.weight\n",
      "layer2.norm.bias\n",
      "layer2.norm.running_mean\n",
      "layer2.norm.running_var\n",
      "layer2.norm.num_batches_tracked\n",
      "layer3.conv.up_conv.weight\n",
      "layer3.conv.up_conv.bias\n",
      "layer3.conv.down_conv.weight\n",
      "layer3.conv.down_conv.bias\n",
      "layer3.norm.weight\n",
      "layer3.norm.bias\n",
      "layer3.norm.running_mean\n",
      "layer3.norm.running_var\n",
      "layer3.norm.num_batches_tracked\n",
      "linear.weight\n",
      "linear.bias\n"
     ]
    }
   ],
   "source": [
    "for k, v in nnew_params.items():\n",
    "    print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([13, 64, 3, 3])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nnew_params['layer1.conv.up_conv.weight'].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 10])\n",
      "conv RANK is: 2\n",
      "conv RANK is: 13\n",
      "conv RANK is: 26\n",
      "conv RANK is: 52\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(2, 3, 32, 32)\n",
    "model1 = conv([3],  [64, 128, 256, 512], 10)\n",
    "print(model1(x).size())\n",
    "# print(model)\n",
    "replace_model(model1, 0.125)\n",
    "# model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.load_state_dict(nnew_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "dx = torch.ones((4, 7, 8))\n",
    "dy = torch.ones((4, 7, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_params = OrderedDict()\n",
    "zero_params = OrderedDict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in nnew_params.items():\n",
    "    one_params[k] = torch.ones(v.size())\n",
    "    zero_params[k] = torch.zeros(v.size())\n",
    "# one_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import merge_list_params\n",
    "two_params = merge_list_params([one_params, zero_params])\n",
    "# two_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadmodel(model, params):\n",
    "    model.load_state_dict(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "loadmodel(model1, two_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model1.layer0.conv.up_conv.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
